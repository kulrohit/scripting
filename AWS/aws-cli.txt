To list of instances 
$/usr/local/bin/list_instances -r ${region} --headers PrivateIP,T:Name

To describe describe instance 
$export EC2_HOME=/usr/local/ec2/ec2-api-tools-1.7.5.1
$export PATH=$PATH:$EC2_HOME/bin 
$export JAVA_HOME=$(/usr/libexec/java_home)
$ec2-describe-instances --region <region> -O <AccessKEY>  -W <Secret key> 

Deleting instance using shell script 
#!/bin/bash
export AWS_CONFIG_FILE='AWS_CONFIG'  # keep your access key, secret key , region info here
instance_id=$3  #Argument 1, which instance need to be deleted 
#check if any other volume is attached to instance
vol=$(aws --profile $1  ec2 describe-volumes --region $2 --filters Name=attachment.instance-id,Values=${instance_id} | jq .Volumes[1].Attachments[0].VolumeId | sed 's/"//g')
# check volume status,size or other info 
echo $vol
#detach volume from instance 
aws --profile $1 ec2 detach-volume --region $2 --volume-id ${vol}  
#delete dettached volume 
aws --profile $1 ec2 delete-volume --region $2 --volume-id ${vol}
#Change termination behavior of instance to terminate , If instance is protected from accidental termination, it wont delete untill behaviour is chaged 
aws --profile $1 --region $1 ec2 modify-instance-attribute --instance-id ${instance_id} --disable-api-termination  "{\"Value\": false}"
#Delet instance 
aws --profile $1 --region $2 ec2 terminate-instances --instance-ids ${instance_id}
# AWS Cloudwatch CLI 
aws cloudwatch get-metric-statistics --namespace AWS/RDS  --metric-name ${metric} --start-time ${STARTTIME} --end-time ${ENDTIME} --period 600  --statistics Average --region us-east-1 --output text | tail -1 | awk '{printf("%d\n",$2 + 0.5)}')
--namespace e.g AWS/RDS,AWS/Redshift,AWS/EC2 etc 
--metrics-name get list from aws cloudwatch , specific names for specific services 
--start-time --endtime are required, 
--region is mandatory 
STARTTIME=`date -d "-15 minutes" "+%Y-%m-%dT%H:%M:%SZ"`
ENDTIME=`date -d "-5 minutes" "+%Y-%m-%dT%H:%M:%SZ"`



##Run chef receipe from remote 
You could use knife ssh to run chef-client on all boxes that contain a certain role or recipe:

knife ssh "role:web" "sudo chef-client" -x ubuntu --sudo 

Or if you're in EC2:

knife ssh "role:web" "sudo chef-client" -x ubuntu -a ec2.public_hostname 


knife ssh name:mynode -a ipaddress  -x ubuntu -i mycredentials.pem "sudo chef-client"You could use knife ssh to run chef-client on all boxes that contain a certain role or recipe:

##Bootstrap Remote node

knife bootstrap new-host-ip -x root -P password -N node_name


#To add a role or recipe to a node
knife node run_list add node_name "recipe[cookbook::recipe]"
knife node run_list add node_name "role[role_name]"
knife node run_list add node_name "role[role_name],recipe[cookbook::recipe]"

##Given a hostname pattern of 'host-<company>-<hostclass>-<index>' (i.e. host-apple-puppet-0) write a custom fact that extracts the <company> value and assigns it to the variable 'company' in facter.

ANS 
======
Facter.add("comapny") do
   setcode do
        Facter::Util::Resolution.exec('hostname | cut -d"-" -f2')
   end
end
=======

List available volumes 
============
for region in  us-east-2 us-east-1	us-west-1 us-west-2	ap-south-1 ap-northeast-2 ap-southeast-1 ap-southeast-2 ap-northeast-1 ca-central-1 eu-central-1 eu-west-1	eu-west-2	
do 
aws --profile wfx-nonprod --region $region ec2 describe-volumes --filters Name=status,Values=available --output text
done 
=========

Volume : 
For i in  vol-a1e9e9ef vol-3c0aa1db vol-c983522f vol-ff825319 vol-88f74a8d vol-c2f74ac7 vol-ebc866f9 vol-58c6fb4a vol-9e803f5f vol-14803fd5 vol-3f8e323e vol-b58e32b4 vol-53f4c842 vol-69ddbf79 vol-3e82d7ca vol-f58dd801 ; do aws --region us-west-2 ec2 delete-volume --volume-id  $i ; done 

Snapshot :
for i in snap-01cdbc8b snap-01cdbc8b snap-056b2e9c snap-046b2e9d snap-0bbd21fb snap-01cdbc8b snap-01cdbc8b snap-056b2e9c snap-046b2e9d snap-0bbd21fb snap-01cdbc8b snap-01cdbc8b snap-056b2e9c snap-046b2e9d ; do aws --profile wfx-nonprod  ec2 --region us-west-2  delete-snapshot --snapshot-id $i 
